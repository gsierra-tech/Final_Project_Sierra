{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#import matplotlib.pyplot as plt\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransforms\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Library imports\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset Loader and Visualization\n",
    "\n",
    "# Fetch the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "\n",
    "# Extract data and labels\n",
    "x, y = mnist['data'], mnist['target']\n",
    "y = y.astype(int)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                      download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        # Convolutional layer 1: 1 input channel (grayscale), 32 output channels (filters), 3x3 kernel size\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        # Convolutional layer 2: 32 input channels, 64 output channels, 3x3 kernel size\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Max-pooling layer: 2x2 pooling size\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Fully connected layer 1 (flattened): 64 channels * 7 * 7 (after two pooling operations)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        # Fully connected output layer (10 classes for digit classification)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply conv1, ReLU activation, and pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # Apply conv2, ReLU activation, and pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        # Flatten the tensor before passing it to the fully connected layers\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "\n",
    "        # Apply fully connected layer 1 and ReLU activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        # Output layer (no activation here, we'll apply softmax during evaluation)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation for the training dataset\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomRotation(10),  # Randomly rotate the image by up to 10 degrees\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),  # Random affine transformation (translation)\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize the image (same as before)\n",
    "])\n",
    "\n",
    "# Define the transform for the test dataset (no augmentation)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize the image (same as before)\n",
    "])\n",
    "\n",
    "# Load the MNIST training dataset with data augmentation\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)  # Loading with augmentation\n",
    "\n",
    "# Load the MNIST test dataset without augmentation\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform_test)  # Loading without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.2297\n",
      "Epoch [2/5], Loss: 0.3483\n",
      "Epoch [3/5], Loss: 0.2205\n",
      "Epoch [4/5], Loss: 0.1692\n",
      "Epoch [5/5], Loss: 0.1387\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the CNN model\n",
    "model = SimpleCNN()  # Create an instance of the CNN class\n",
    "\n",
    "# Loss function and optimizer for CNN (same as FCNN)\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  # Stochastic Gradient Descent (you can also try Adam)\n",
    "\n",
    "# Set up the DataLoader for training\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "\n",
    "# Training loop for the CNN model\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "     # Iterate over batches of data\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.view(-1, 1, 28, 28)  # Ensure the correct shape\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(inputs)  # Pass the inputs through the CNN model\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backpropagate the gradients\n",
    "        optimizer.step()  # Update the model parameters\n",
    "        running_loss += loss.item()  # Accumulate the loss for logging\n",
    "\n",
    "    # Print the loss after each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.93%\n"
     ]
    }
   ],
   "source": [
    "# Set up the DataLoader for testing\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False)\n",
    "\n",
    "# Evaluate the CNN model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)  # Pass the inputs through the CNN model\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the class with the highest probability\n",
    "        total += labels.size(0)  # Increment total samples\n",
    "        correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as cnn_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"cnn_model.pth\")  # Save the model parameters\n",
    "print(\"Model saved as cnn_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist = datasets.MNIST(root='./data', train=True, download=True)\n",
    "\n",
    "# Get a random image and its label\n",
    "image, label = mnist[5]  # Change the index to get different images\n",
    "\n",
    "# Display the image directly\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.show()\n",
    "\n",
    "# Save the image as a PNG file\n",
    "image.save('mnist_sample.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
